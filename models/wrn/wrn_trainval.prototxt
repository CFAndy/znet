name: "wrn_128_v8"
layer {
  name: "input-data"
  type: "Python"
  top: "data"
  top: "label"
  include {
     phase: TRAIN
  }
  python_param {
    module: 'unet.datalayer'
    layer: 'DataLayer'
  }
}

layer {
  name: "input-data"
  type: "Python"
  top: "data"
  top: "label"
  include {
     phase: TEST
  }
  python_param {
    module: 'unet.datalayer'
    layer: 'ValDataLayer'
  }
}

layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "data"
  top: "Convolution1"
  convolution_param {
    engine: MKL2017
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
  relu_param {
        engine: MKL2017
  }
}

layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  batch_norm_param {
    engine: MKL2017
    use_global_stats: false
  }
}

################
layer {
  name: "block1_conv"
  type: "Convolution"
  bottom: "Convolution1"
  top: "block1_conv"
  convolution_param {
    engine: MKL2017
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
  name: "block1_relu"
  type: "ReLU"
  bottom: "block1_conv"
  top: "block1_conv"
  relu_param {
        engine: MKL2017
  }
}

layer {
  name: "block1_bn1"
  type: "BatchNorm"
  bottom: "block1_conv"
  top: "block1_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  batch_norm_param {
    engine: MKL2017
    use_global_stats: false
  }
}

layer {
  name: "block1_drop"
  type: "Dropout"
  bottom: "block1_conv"
  top: "block1_drop"
  dropout_param {
    dropout_ratio: 0.3
  }
}

layer {
  name: "block1_conv2"
  type: "Convolution"
  bottom: "block1_drop"
  top: "block1_conv2"
  convolution_param {
    engine: MKL2017
	num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
  name: "block1_conv3"
  type: "Convolution"
  bottom: "block1_conv2"
  top: "block1_conv3"
  convolution_param {
    engine: MKL2017
	num_output: 32
    pad: 0 
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
        bottom: "block1_conv2"
        bottom: "block1_conv3"
        top: "block1"
        name: "block1"
        type: "Eltwise"
        eltwise_param {
                engine: MKL2017
        }
}

#############################
layer {
  name: "block2_BatchNorm1"
  type: "BatchNorm"
  bottom: "block1"
  top: "block2_in"
  param {
    lr_mult: 1 
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  batch_norm_param {
    engine: MKL2017
    use_global_stats: false
  }
}

layer {
  name: "block2_ReLU1"
  type: "ReLU"
  bottom: "block2_in"
  top: "block2_in"
  relu_param {
        engine: MKL2017
  }
}

layer {
  name: "block2_conv"
  type: "Convolution"
  bottom: "block2_in"
  top: "block2_conv"
  convolution_param {
    engine: MKL2017
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
  name: "block2_relu2"
  type: "ReLU"
  bottom: "block2_conv"
  top: "block2_conv"
  relu_param {
        engine: MKL2017
  }
}

layer {
  name: "block2_BatchNorm2"
  type: "BatchNorm"
  bottom: "block2_conv"
  top: "block2_conv"
  param {
    lr_mult: 1 
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  batch_norm_param {
    engine: MKL2017
    use_global_stats: false
  }
}

layer {
  name: "block2_drop"
  type: "Dropout"
  bottom: "block2_conv"
  top: "block2_drop"
  dropout_param {
    dropout_ratio: 0.3
  }
}

layer {
  name: "block2_conv2"
  type: "Convolution"
  bottom: "block2_drop"
  top: "block2_conv2"
  convolution_param {
    engine: MKL2017
	num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
        bottom: "block2_conv2"
        bottom: "block1"
        top: "block2"
        name: "block2"
        type: "Eltwise"
        eltwise_param {
                engine: MKL2017
        }
}


#####################
layer {
  name: "block3_BatchNorm1"
  type: "BatchNorm"
  bottom: "block2"
  top: "block3_in"
  param {
    lr_mult: 1 
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  batch_norm_param {
    engine: MKL2017
    use_global_stats: false
  }
}

layer {
  name: "block3_ReLU1"
  type: "ReLU"
  bottom: "block3_in"
  top: "block3_in"
  relu_param {
        engine: MKL2017
  }
}

layer {
  name: "block3_conv"
  type: "Convolution"
  bottom: "block3_in"
  top: "block3_conv"
  convolution_param {
    engine: MKL2017
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
  name: "block3_ReLU2"
  type: "ReLU"
  bottom: "block3_conv"
  top: "block3_conv"
  relu_param {
        engine: MKL2017
  }
}

layer {
  name: "block3_BatchNorm2"
  type: "BatchNorm"
  bottom: "block3_conv"
  top: "block3_conv"
  param {
    lr_mult: 1 
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  batch_norm_param {
    engine: MKL2017
    use_global_stats: false
  }
}

layer {
  name: "block3_drop"
  type: "Dropout"
  bottom: "block3_conv"
  top: "block3_drop"
  dropout_param {
    dropout_ratio: 0.3
  }
}

layer {
  name: "block3_conv2"
  type: "Convolution"
  bottom: "block3_drop"
  top: "block3_conv2"
  convolution_param {
    engine: MKL2017
	num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
        bottom: "block3_conv2"
        bottom: "block2"
        top: "block3"
        name: "block3"
        type: "Eltwise"
        eltwise_param {
                engine: MKL2017
        }
}


#####################
layer {
  name: "block4_BatchNorm1"
  type: "BatchNorm"
  bottom: "block3"
  top: "block4_in"
  param {
    lr_mult: 1 
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  batch_norm_param {
    engine: MKL2017
    use_global_stats: false
  }
}
layer {
  name: "block4_ReLU1"
  type: "ReLU"
  bottom: "block4_in"
  top: "block4_in"
  relu_param {
        engine: MKL2017
  }
}
layer {
  name: "block4_conv"
  type: "Convolution"
  bottom: "block4_in"
  top: "block4_conv"
  convolution_param {
    engine: MKL2017
    num_output: 32
    pad:1 
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "block4_ReLU2"
  type: "ReLU"
  bottom: "block4_conv"
  top: "block4_conv"
  relu_param {
        engine: MKL2017
  }
}
layer {
  name: "block4_BatchNorm2"
  type: "BatchNorm"
  bottom: "block4_conv"
  top: "block4_conv"
  param {
    lr_mult: 1 
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  batch_norm_param {
    engine: MKL2017
    use_global_stats: false
  }
}
layer {
  name: "block4_drop"
  type: "Dropout"
  bottom: "block4_conv"
  top: "block4_drop"
  dropout_param {
    dropout_ratio: 0.3
  }
}
layer {
  name: "block4_conv2"
  type: "Convolution"
  bottom: "block4_drop"
  top: "block4_conv2"
  convolution_param {
    engine: MKL2017
	num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
        bottom: "block4_conv2"
        bottom: "block3"
        top: "block4"
        name: "block4"
        type: "Eltwise"
        eltwise_param {
                engine: MKL2017
        }
}
#####################
layer {
  name: "block5_BatchNorm1"
  type: "BatchNorm"
  bottom: "block4"
  top: "block5_in"
  param {
    lr_mult: 1 
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  batch_norm_param {
    engine: MKL2017
    use_global_stats: false
  }
}
layer {
  name: "block5_ReLU1"
  type: "ReLU"
  bottom: "block5_in"
  top: "block5_in"
  relu_param {
        engine: MKL2017
  }
}
layer {
  name: "block5_conv"
  type: "Convolution"
  bottom: "block5_in"
  top: "block5_conv"
  convolution_param {
    engine: MKL2017
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "block5_ReLU2"
  type: "ReLU"
  bottom: "block5_conv"
  top: "block5_conv"
  relu_param {
        engine: MKL2017
  }
}
layer {
  name: "block5_BatchNorm2"
  type: "BatchNorm"
  bottom: "block5_conv"
  top: "block5_conv"
  param {
    lr_mult: 1 
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  batch_norm_param {
    engine: MKL2017
    use_global_stats: false
  }
}
layer {
  name: "block5_drop"
  type: "Dropout"
  bottom: "block5_conv"
  top: "block5_drop"
  dropout_param {
    dropout_ratio: 0.3
  }
}
layer {
  name: "block5_conv2"
  type: "Convolution"
  bottom: "block5_drop"
  top: "block5_conv2"
  convolution_param {
    engine: MKL2017
	num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
        bottom: "block5_conv2"
        bottom: "block4"
        top: "block5"
        name: "block5"
        type: "Eltwise"
        eltwise_param {
                engine: MKL2017
        }
}
####################
layer {
  name: "block9_BatchNorm1"
  type: "BatchNorm"
  bottom: "block5"
  top: "block9_in"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  batch_norm_param {
    engine: MKL2017
    use_global_stats: false
  }
}
layer {
  name: "block9_ReLU1"
  type: "ReLU"
  bottom: "block9_in"
  top: "block9_in"
  relu_param {
        engine: MKL2017
  }
}
layer {
  name: "block9_conv"
  type: "Convolution"
  bottom: "block9_in"
  top: "block9_conv"
  convolution_param {
    engine: MKL2017
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "block9_ReLU2"
  type: "ReLU"
  bottom: "block9_conv"
  top: "block9_conv"
  relu_param {
        engine: MKL2017
  }
}
layer {
  name: "block9_BatchNorm2"
  type: "BatchNorm"
  bottom: "block9_conv"
  top: "block9_conv"
  param {
    lr_mult: 1 
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  batch_norm_param {
    engine: MKL2017
    use_global_stats: false
  }
}
layer {
  name: "block9_drop"
  type: "Dropout"
  bottom: "block9_conv"
  top: "block9_drop"
  dropout_param {
    dropout_ratio: 0.3
  }
}
layer {
  name: "block9_conv2"
  type: "Convolution"
  bottom: "block9_drop"
  top: "block9_conv2"
  convolution_param {
    engine: MKL2017
	num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "block9_conv3"
  type: "Convolution"
  bottom: "block5"
  top: "block9_conv3"
  convolution_param {
    engine: MKL2017
	num_output: 64
    pad: 0 
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
        bottom: "block9_conv2"
        bottom: "block9_conv3"
        top: "block9"
        name: "block9"
        type: "Eltwise"
        eltwise_param {
                engine: MKL2017
        }
}
#####################
layer {
  name: "block10_BatchNorm1"
  type: "BatchNorm"
  bottom: "block9"
  top: "block10_in"
  param {
    lr_mult: 1 
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  batch_norm_param {
    engine: MKL2017
    use_global_stats: false
  }
}
layer {
  name: "block10_ReLU1"
  type: "ReLU"
  bottom: "block10_in"
  top: "block10_in"
  relu_param {
        engine: MKL2017
  }
}
layer {
  name: "block10_conv"
  type: "Convolution"
  bottom: "block10_in"
  top: "block10_conv"
  convolution_param {
    engine: MKL2017
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "block10_ReLU2"
  type: "ReLU"
  bottom: "block10_conv"
  top: "block10_conv"
  relu_param {
        engine: MKL2017
  }
}
layer {
  name: "block10_BatchNorm2"
  type: "BatchNorm"
  bottom: "block10_conv"
  top: "block10_conv"
  param {
    lr_mult: 1 
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  batch_norm_param {
    engine: MKL2017
    use_global_stats: false
  }
}

layer {
  name: "block10_drop"
  type: "Dropout"
  bottom: "block10_conv"
  top: "block10_drop"
  dropout_param {
    dropout_ratio: 0.3
  }
}
layer {
  name: "block10_conv2"
  type: "Convolution"
  bottom: "block10_drop"
  top: "block10_conv2"
  convolution_param {
    engine: MKL2017
	num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
        bottom: "block10_conv2"
        bottom: "block9"
        top: "block10"
        name: "block10"
        type: "Eltwise"
        eltwise_param {
                engine: MKL2017
        }
}
#####################
layer {
  name: "block11_BatchNorm1"
  type: "BatchNorm"
  bottom: "block10"
  top: "block11_in"
  param {
    lr_mult: 1 
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  batch_norm_param {
    engine: MKL2017
    use_global_stats: false
  }
}
layer {
  name: "block11_ReLU1"
  type: "ReLU"
  bottom: "block11_in"
  top: "block11_in"
  relu_param {
        engine: MKL2017
  }
}
layer {
  name: "block11_conv"
  type: "Convolution"
  bottom: "block11_in"
  top: "block11_conv"
  convolution_param {
    engine: MKL2017
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "block11_ReLU2"
  type: "ReLU"
  bottom: "block11_conv"
  top: "block11_conv"
  relu_param {
        engine: MKL2017
  }
}
layer {
  name: "block11_BatchNorm2"
  type: "BatchNorm"
  bottom: "block11_conv"
  top: "block11_conv"
  param {
    lr_mult: 1 
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  batch_norm_param {
    engine: MKL2017
    use_global_stats: false
  }
}

layer {
  name: "block11_drop"
  type: "Dropout"
  bottom: "block11_conv"
  top: "block11_drop"
  dropout_param {
    dropout_ratio: 0.3
  }
}
layer {
  name: "block11_conv2"
  type: "Convolution"
  bottom: "block11_drop"
  top: "block11_conv2"
  convolution_param {
    engine: MKL2017
	num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
        bottom: "block11_conv2"
        bottom: "block10"
        top: "block11"
        name: "block11"
        type: "Eltwise"
        eltwise_param {
                engine: MKL2017
        }
}

#####################
layer {
  name: "block12_BatchNorm1"
  type: "BatchNorm"
  bottom: "block11"
  top: "block12_in"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  batch_norm_param {
    engine: MKL2017
    use_global_stats: false
  }
}
layer {
  name: "block12_ReLU1"
  type: "ReLU"
  bottom: "block12_in"
  top: "block12_in"
  relu_param {
        engine: MKL2017
  }
}
layer {
  name: "block12_conv"
  type: "Convolution"
  bottom: "block12_in"
  top: "block12_conv"
  convolution_param {
    engine: MKL2017
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "block12_ReLU2"
  type: "ReLU"
  bottom: "block12_conv"
  top: "block12_conv"
  relu_param {
        engine: MKL2017
  }
}
layer {
  name: "block12_BatchNorm2"
  type: "BatchNorm"
  bottom: "block12_conv"
  top: "block12_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  batch_norm_param {
    engine: MKL2017
    use_global_stats: false
  }
}
layer {
  name: "block12_drop"
  type: "Dropout"
  bottom: "block12_conv"
  top: "block12_drop"
  dropout_param {
    dropout_ratio: 0.3
  }
}
layer {
  name: "block12_conv2"
  type: "Convolution"
  bottom: "block12_drop"
  top: "block12_conv2"
  convolution_param {
    engine: MKL2017
	num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
        bottom: "block12_conv2"
        bottom: "block11"
        top: "block12"
        name: "block12"
        type: "Eltwise"
        eltwise_param {
                engine: MKL2017
        }
}
#####################
layer {
  name: "block13_BatchNorm1"
  type: "BatchNorm"
  bottom: "block12"
  top: "block13_in"
  param {
    lr_mult: 1 
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  batch_norm_param {
    engine: MKL2017
    use_global_stats: false
  }
}
layer {
  name: "block13_ReLU1"
  type: "ReLU"
  bottom: "block13_in"
  top: "block13_in"
  relu_param {
        engine: MKL2017
  }
}
layer {
  name: "block13_conv"
  type: "Convolution"
  bottom: "block13_in"
  top: "block13_conv"
  convolution_param {
    engine: MKL2017
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "block13_ReLU2"
  type: "ReLU"
  bottom: "block13_conv"
  top: "block13_conv"
  relu_param {
        engine: MKL2017
  }
}
layer {
  name: "block13_BatchNorm2"
  type: "BatchNorm"
  bottom: "block13_conv"
  top: "block13_conv"
  param {
    lr_mult: 1 
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  batch_norm_param {
    engine: MKL2017
    use_global_stats: false
  }
}
layer {
  name: "block13_drop"
  type: "Dropout"
  bottom: "block13_conv"
  top: "block13_drop"
  dropout_param {
    dropout_ratio: 0.3
  }
}
layer {
  name: "block13_conv2"
  type: "Convolution"
  bottom: "block13_drop"
  top: "block13_conv2"
  convolution_param {
    engine: MKL2017
	num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
        bottom: "block13_conv2"
        bottom: "block12"
        top: "block13"
        name: "block13"
        type: "Eltwise"
        eltwise_param {
                engine: MKL2017
        }
}
#####################
layer {
  name: "block14_BatchNorm1"
  type: "BatchNorm"
  bottom: "block13"
  top: "block14_in"
  param {
    lr_mult: 1 
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  batch_norm_param {
    engine: MKL2017
    use_global_stats: false
  }
}
layer {
  name: "block14_ReLU1"
  type: "ReLU"
  bottom: "block14_in"
  top: "block14_in"
  relu_param {
        engine: MKL2017
  }
}
layer {
  name: "block14_conv"
  type: "Convolution"
  bottom: "block14_in"
  top: "block14_conv"
  convolution_param {
    engine: MKL2017
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "block14_ReLU2"
  type: "ReLU"
  bottom: "block14_conv"
  top: "block14_conv"
  relu_param {
        engine: MKL2017
  }
}
layer {
  name: "block14_BatchNorm2"
  type: "BatchNorm"
  bottom: "block14_conv"
  top: "block14_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  batch_norm_param {
    engine: MKL2017
    use_global_stats: false
  }
}
layer {
  name: "block14_drop"
  type: "Dropout"
  bottom: "block14_conv"
  top: "block14_drop"
  dropout_param {
    dropout_ratio: 0.3
  }
}
layer {
  name: "block14_conv2"
  type: "Convolution"
  bottom: "block14_drop"
  top: "block14_conv2"
  convolution_param {
    engine: MKL2017
	num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
        bottom: "block14_conv2"
        bottom: "block13"
        top: "block14"
        name: "block14"
        type: "Eltwise"
        eltwise_param {
                engine: MKL2017
        }
}
#####################
layer {
  name: "block15_BatchNorm1"
  type: "BatchNorm"
  bottom: "block14"
  top: "block15_in"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  batch_norm_param {
    engine: MKL2017
    use_global_stats: false
  }
}
layer {
  name: "block15_ReLU1"
  type: "ReLU"
  bottom: "block15_in"
  top: "block15_in"
  relu_param {
        engine: MKL2017
  }
}
layer {
  name: "block15_conv"
  type: "Convolution"
  bottom: "block15_in"
  top: "block15_conv"
  convolution_param {
    engine: MKL2017
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "block15_ReLU2"
  type: "ReLU"
  bottom: "block15_conv"
  top: "block15_conv"
  relu_param {
        engine: MKL2017
  }
}
layer {
  name: "block15_BatchNorm2"
  type: "BatchNorm"
  bottom: "block15_conv"
  top: "block15_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  batch_norm_param {
    engine: MKL2017
    use_global_stats: false
  }
}
layer {
  name: "block15_drop"
  type: "Dropout"
  bottom: "block15_conv"
  top: "block15_drop"
  dropout_param {
    dropout_ratio: 0.3
  }
}
layer {
  name: "block15_conv2"
  type: "Convolution"
  bottom: "block15_drop"
  top: "block15_conv2"
  convolution_param {
    engine: MKL2017
	num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
        bottom: "block15_conv2"
        bottom: "block14"
        top: "block15"
        name: "block15"
        type: "Eltwise"
        eltwise_param {
                engine: MKL2017
        }
}
#####################
layer {
  name: "block16_BatchNorm1"
  type: "BatchNorm"
  bottom: "block15"
  top: "block16_in"
  param {
    lr_mult: 1 
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  batch_norm_param {
    engine: MKL2017
    use_global_stats: false
  }
}
layer {
  name: "block16_ReLU1"
  type: "ReLU"
  bottom: "block16_in"
  top: "block16_in"
  relu_param {
        engine: MKL2017
  }
}
layer {
  name: "block16_conv"
  type: "Convolution"
  bottom: "block16_in"
  top: "block16_conv"
  convolution_param {
    engine: MKL2017
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "block16_ReLU2"
  type: "ReLU"
  bottom: "block16_conv"
  top: "block16_conv"
  relu_param {
        engine: MKL2017
  }
}
layer {
  name: "block16_BatchNorm2"
  type: "BatchNorm"
  bottom: "block16_conv"
  top: "block16_conv"
  param {
    lr_mult: 1 
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  batch_norm_param {
    engine: MKL2017
    use_global_stats: false
  }
}
layer {
  name: "block16_drop"
  type: "Dropout"
  bottom: "block16_conv"
  top: "block16_drop"
  dropout_param {
    dropout_ratio: 0.3
  }
}
layer {
  name: "block16_conv2"
  type: "Convolution"
  bottom: "block16_drop"
  top: "block16_conv2"
  convolution_param {
    engine: MKL2017
	num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "block16_conv3"
  type: "Convolution"
  bottom: "block15"
  top: "block16_conv3"
  convolution_param {
    engine: MKL2017
	num_output: 128
    pad: 0 
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
        bottom: "block16_conv2"
        bottom: "block16_conv3"
        top: "block16"
        name: "block16"
        type: "Eltwise"
        eltwise_param {
                engine: MKL2017
        }
}
#####################
layer {
  name: "block17_BatchNorm1"
  type: "BatchNorm"
  bottom: "block16"
  top: "block17_in"
  param {
    lr_mult: 1 
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  batch_norm_param {
    engine: MKL2017
    use_global_stats: false
  }
}
layer {
  name: "block17_ReLU1"
  type: "ReLU"
  bottom: "block17_in"
  top: "block17_in"
  relu_param {
        engine: MKL2017
  }
}
layer {
  name: "block17_conv"
  type: "Convolution"
  bottom: "block17_in"
  top: "block17_conv"
  convolution_param {
    engine: MKL2017
    num_output: 128
    pad:1 
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "block17_ReLU2"
  type: "ReLU"
  bottom: "block17_conv"
  top: "block17_conv"
  relu_param {
        engine: MKL2017
  }
}
layer {
  name: "block17_BatchNorm2"
  type: "BatchNorm"
  bottom: "block17_conv"
  top: "block17_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  batch_norm_param {
    engine: MKL2017
    use_global_stats: false
  }
}
layer {
  name: "block17_drop"
  type: "Dropout"
  bottom: "block17_conv"
  top: "block17_drop"
  dropout_param {
    dropout_ratio: 0.3
  }
}
layer {
  name: "block17_conv2"
  type: "Convolution"
  bottom: "block17_drop"
  top: "block17_conv2"
  convolution_param {
    engine: MKL2017
	num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
        bottom: "block17_conv2"
        bottom: "block16"
        top: "block17"
        name: "block17"
        type: "Eltwise"
        eltwise_param {
                engine: MKL2017
        }
}

#####################
layer {
  name: "block18_BatchNorm1"
  type: "BatchNorm"
  bottom: "block17"
  top: "block18_in"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  batch_norm_param {
    engine: MKL2017
    use_global_stats: false
  }
}
layer {
  name: "block18_ReLU1"
  type: "ReLU"
  bottom: "block18_in"
  top: "block18_in"
  relu_param {
        engine: MKL2017
  }
}
layer {
  name: "block18_conv"
  type: "Convolution"
  bottom: "block18_in"
  top: "block18_conv"
  convolution_param {
    engine: MKL2017
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "block18_ReLU2"
  type: "ReLU"
  bottom: "block18_conv"
  top: "block18_conv"
  relu_param {
        engine: MKL2017
  }
}
layer {
  name: "block18_BatchNorm2"
  type: "BatchNorm"
  bottom: "block18_conv"
  top: "block18_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  batch_norm_param {
    engine: MKL2017
    use_global_stats: false
  }
}

layer {
  name: "block18_drop"
  type: "Dropout"
  bottom: "block18_conv"
  top: "block18_drop"
  dropout_param {
    dropout_ratio: 0.3
  }
}
layer {
  name: "block18_conv2"
  type: "Convolution"
  bottom: "block18_drop"
  top: "block18_conv2"
  convolution_param {
    engine: MKL2017
	num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
        bottom: "block18_conv2"
        bottom: "block17"
        top: "block18"
        name: "block18"
        type: "Eltwise"
        eltwise_param {
                engine: MKL2017
        }
}
#####################
layer {
  name: "block19_BatchNorm1"
  type: "BatchNorm"
  bottom: "block18"
  top: "block19_in"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  batch_norm_param {
    engine: MKL2017
    use_global_stats: false
  }
}
layer {
  name: "block19_ReLU1"
  type: "ReLU"
  bottom: "block19_in"
  top: "block19_in"
  relu_param {
        engine: MKL2017
  }
}
layer {
  name: "block19_conv"
  type: "Convolution"
  bottom: "block19_in"
  top: "block19_conv"
  convolution_param {
    engine: MKL2017
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "block19_ReLU2"
  type: "ReLU"
  bottom: "block19_conv"
  top: "block19_conv"
  relu_param {
        engine: MKL2017
  }
}
layer {
  name: "block19_BatchNorm2"
  type: "BatchNorm"
  bottom: "block19_conv"
  top: "block19_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  batch_norm_param {
    engine: MKL2017
    use_global_stats: false
  }
}

layer {
  name: "block19_drop"
  type: "Dropout"
  bottom: "block19_conv"
  top: "block19_drop"
  dropout_param {
    dropout_ratio: 0.3
  }
}
layer {
  name: "block19_conv2"
  type: "Convolution"
  bottom: "block19_drop"
  top: "block19_conv2"
  convolution_param {
    engine: MKL2017
	num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
        bottom: "block19_conv2"
        bottom: "block18"
        top: "block19"
        name: "block19"
        type: "Eltwise"
        eltwise_param {
                engine: MKL2017
        }
}
#####################
layer {
  name: "block20_BatchNorm1"
  type: "BatchNorm"
  bottom: "block19"
  top: "block20_in"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  batch_norm_param {
    engine: MKL2017
    use_global_stats: false
  }
}
layer {
  name: "block20_ReLU1"
  type: "ReLU"
  bottom: "block20_in"
  top: "block20_in"
  relu_param {
        engine: MKL2017
  }
}
layer {
  name: "block20_conv"
  type: "Convolution"
  bottom: "block20_in"
  top: "block20_conv"
  convolution_param {
    engine: MKL2017
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "block20_ReLU2"
  type: "ReLU"
  bottom: "block20_conv"
  top: "block20_conv"
  relu_param {
        engine: MKL2017
  }
}
layer {
  name: "block20_BatchNorm2"
  type: "BatchNorm"
  bottom: "block20_conv"
  top: "block20_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  batch_norm_param {
    engine: MKL2017
    use_global_stats: false
  }
}

layer {
  name: "block20_drop"
  type: "Dropout"
  bottom: "block20_conv"
  top: "block20_drop"
  dropout_param {
    dropout_ratio: 0.3
  }
}
layer {
  name: "block20_conv2"
  type: "Convolution"
  bottom: "block20_drop"
  top: "block20_conv2"
  convolution_param {
    engine: MKL2017
	num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
        bottom: "block20_conv2"
        bottom: "block19"
        top: "block20"
        name: "block20"
        type: "Eltwise"
        eltwise_param {
                engine: MKL2017
        }
}
#####################
layer {
  name: "block21_BatchNorm1"
  type: "BatchNorm"
  bottom: "block20"
  top: "block21_in"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  batch_norm_param {
    engine: MKL2017
    use_global_stats: false
  }
}
layer {
  name: "block21_ReLU1"
  type: "ReLU"
  bottom: "block21_in"
  top: "block21_in"
  relu_param {
        engine: MKL2017
  }
}
layer {
  name: "block21_conv"
  type: "Convolution"
  bottom: "block21_in"
  top: "block21_conv"
  convolution_param {
    engine: MKL2017
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "block21_ReLU2"
  type: "ReLU"
  bottom: "block21_conv"
  top: "block21_conv"
  relu_param {
        engine: MKL2017
  }
}
layer {
  name: "block21_BatchNorm2"
  type: "BatchNorm"
  bottom: "block21_conv"
  top: "block21_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  batch_norm_param {
    engine: MKL2017
    use_global_stats: false
  }
}
layer {
  name: "block21_drop"
  type: "Dropout"
  bottom: "block21_conv"
  top: "block21_drop"
  dropout_param {
    dropout_ratio: 0.3
  }
}
layer {
  name: "block21_conv2"
  type: "Convolution"
  bottom: "block21_drop"
  top: "block21_conv2"
  convolution_param {
    engine: MKL2017
	num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
        bottom: "block21_conv2"
        bottom: "block20"
        top: "block21"
        name: "block21"
        type: "Eltwise"
        eltwise_param {
                engine: MKL2017
        }
}
#####################
layer {
  name: "block22_BatchNorm1"
  type: "BatchNorm"
  bottom: "block21"
  top: "block22_in"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  batch_norm_param {
    engine: MKL2017
    use_global_stats: false
  }
}
layer {
  name: "block22_ReLU1"
  type: "ReLU"
  bottom: "block22_in"
  top: "block22_in"
  relu_param {
        engine: MKL2017
  }
}
layer {
  name: "block22_conv"
  type: "Convolution"
  bottom: "block22_in"
  top: "block22_conv"
  convolution_param {
    engine: MKL2017
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "block22_ReLU2"
  type: "ReLU"
  bottom: "block22_conv"
  top: "block22_conv"
  relu_param {
        engine: MKL2017
  }
}
layer {
  name: "block22_BatchNorm2"
  type: "BatchNorm"
  bottom: "block22_conv"
  top: "block22_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  batch_norm_param {
    engine: MKL2017
    use_global_stats: false
  }
}
layer {
  name: "block22_drop"
  type: "Dropout"
  bottom: "block22_conv"
  top: "block22_drop"
  dropout_param {
    dropout_ratio: 0.3
  }
}
layer {
  name: "block22_conv2"
  type: "Convolution"
  bottom: "block22_drop"
  top: "block22_conv2"
  convolution_param {
    engine: MKL2017
	num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
        bottom: "block22_conv2"
        bottom: "block21"
        top: "block22"
        name: "block22"
        type: "Eltwise"
        eltwise_param {
                engine: MKL2017
        }
}
layer {
  name: "BatchNormLast"
  type: "BatchNorm"
  bottom: "block22"
  top: "block22"
  param {
    lr_mult: 1 
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  batch_norm_param {
    engine: MKL2017
    use_global_stats: false
  }
}
layer {
  name: "LastRelu"
  type: "ReLU"
  bottom: "block22"
  top: "block22"
  relu_param {
        engine: MKL2017
  }
}
layer {
  name: "avgPool"
  type: "Pooling"
  bottom: "block22"
  top: "poolblock"
  pooling_param {
    pool:AVE 
    global_pooling:True
    engine: MKL2017
  }
}
layer {
  name: "fc"
  type: "InnerProduct"
  bottom: "poolblock"
  top: "fc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1 
    decay_mult: 1
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}

layer {
      name: "prob"
      type: "Softmax"
      bottom: "fc"
      top: "prob"
      include {
        phase: TEST    
      }
}

layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc"
  bottom: "label"
  top: "loss"
  include {
    phase: TRAIN    
  }
}

layer {
  name: "top1"
  type: "Accuracy"
  bottom: "prob"
  bottom: "label"
  top: "top1"
  include {
     phase: TEST    
  }
}
